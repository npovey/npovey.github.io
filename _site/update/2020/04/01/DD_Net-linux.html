<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>DD-Net: Combination of DenseNet and Deconvolution (linux) | can code</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="DD-Net: Combination of DenseNet and Deconvolution (linux)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="DenseNet and Deconvolution (linux)" />
<meta property="og:description" content="DenseNet and Deconvolution (linux)" />
<link rel="canonical" href="http://localhost:4000/update/2020/04/01/DD_Net-linux.html" />
<meta property="og:url" content="http://localhost:4000/update/2020/04/01/DD_Net-linux.html" />
<meta property="og:site_name" content="can code" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-01T14:34:33-07:00" />
<script type="application/ld+json">
{"url":"http://localhost:4000/update/2020/04/01/DD_Net-linux.html","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/update/2020/04/01/DD_Net-linux.html"},"description":"DenseNet and Deconvolution (linux)","headline":"DD-Net: Combination of DenseNet and Deconvolution (linux)","dateModified":"2020-04-01T14:34:33-07:00","datePublished":"2020-04-01T14:34:33-07:00","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="can code" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">can code</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">DD-Net: Combination of DenseNet and Deconvolution (linux)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2020-04-01T14:34:33-07:00" itemprop="datePublished">Apr 1, 2020
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="densenet-and-deconvolution-linux">DenseNet and Deconvolution (linux)</h1>

<p>DD-Net always peformed similar to UNet and DnCNN. The training time was the longest out of other 2 models. It took aprox. 24 hours to train the network.</p>

<p>my implementation  <a href="https://github.com/npovey/DD-Net">https://github.com/npovey/DD-Net</a></p>

<p>paper: <a href="https://ieeexplore.ieee.org/document/8331861">https://ieeexplore.ieee.org/document/8331861</a></p>

<p>original paper github: <a href="https://github.com/zzc623/DD_Net">https://github.com/zzc623/DD_Net</a></p>

<p>Authors write “The DD-Net was trained by the Adam algorithm [54].
The learning rate was initially set at 10−4 and slowly decreased
continuously down to 10−5. The size of mini-batch was 5. DD-
Net was implemented using Tensorflow [55] on a personal
workstation with Intel Core i5-7400 CPU and 16GB RAM.
A GPU card (Nvidia GTX Titan X) accelerated the training
process. All the convolution and deconvolution filters were
initialized with random Gaussian distributions with zero mean
and 0.01 standard deviation.”</p>

<p><img src="/2020-04-01-DD-Net-linux/ddnet_paper.png" alt="ddnet_paper" /></p>

<p><strong>Results</strong></p>

<p>The average PSNR and SSIM values over 354 test images are displayed in the table below.</p>

<p>Learning rate 10^-4</p>

<p>40 epochs</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Low Dose Image</th>
      <th style="text-align: left">UNet</th>
      <th>DnCNN</th>
      <th style="text-align: center">DDNet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">sparseview_60</td>
      <td style="text-align: left"><strong>Avg PSNR: 33.28	                        Avg SSIM: 0.8858</strong></td>
      <td>Avg PSNR: 32.30               Avg SSIM: 0.8560</td>
      <td style="text-align: center">Avg PSNR: 32.96	Avg SSIM: 0.8797</td>
    </tr>
    <tr>
      <td style="text-align: left">sparseview_90</td>
      <td style="text-align: left"><strong>Avg PSNR: 35.42	                     Avg SSIM: 0.9038</strong></td>
      <td>Avg PSNR: 35.13               Avg SSIM: 0.8892</td>
      <td style="text-align: center">Avg PSNR: 35.29	Avg SSIM: 0.9011</td>
    </tr>
    <tr>
      <td style="text-align: left">sparseview_180</td>
      <td style="text-align: left">Avg PSNR: 39.48	                    Avg SSIM: 0.9319</td>
      <td><strong>Avg PSNR: 39.77               Avg SSIM: 0.9341</strong></td>
      <td style="text-align: center">Avg PSNR: 39.55	Avg SSIM: 0.9322</td>
    </tr>
    <tr>
      <td style="text-align: left">ldct_7e4</td>
      <td style="text-align: left">Avg PSNR: 41.78	                     Avg SSIM: 0.9429</td>
      <td><strong>Avg PSNR: 42.00	            Avg SSIM: 0.9444</strong></td>
      <td style="text-align: center">Avg PSNR: 41.84	Avg SSIM: 0.9431</td>
    </tr>
    <tr>
      <td style="text-align: left">ldct_1e5</td>
      <td style="text-align: left">Avg PSNR: 42.11	                    Avg SSIM: 0.9441</td>
      <td><strong>Avg PSNR: 42.32	            Avg SSIM: 0.9456</strong></td>
      <td style="text-align: center">Avg PSNR: 42.23	Avg SSIM: 0.9448</td>
    </tr>
    <tr>
      <td style="text-align: left">ldct_2e5</td>
      <td style="text-align: left">Avg PSNR: 42.69	                     Avg SSIM: 0.9466</td>
      <td><strong>Avg PSNR: 42.87	            Avg SSIM: 0.9477</strong></td>
      <td style="text-align: center">Avg PSNR: 42.77	Avg SSIM: 0.9471</td>
    </tr>
  </tbody>
</table>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def denseblock<span class="o">(</span>input<span class="o">)</span>:
  <span class="c"># - L1</span>
  num_filters <span class="o">=</span> 16
  d2_1 <span class="o">=</span> BatchNormalization<span class="o">()(</span>input<span class="o">)</span>
  d2_1 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_1<span class="o">)</span>
  d2_1 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters<span class="k">*</span>4, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_1<span class="o">)</span>

  d2_1 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2_1<span class="o">)</span>
  d2_1 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_1<span class="o">)</span>
  d2_1 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters, <span class="o">(</span>5, 5<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_1<span class="o">)</span>

  d2_1 <span class="o">=</span> concatenate<span class="o">([</span>input, d2_1]<span class="o">)</span>

  <span class="c"># - L2</span>
  d2_2 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2_1<span class="o">)</span>
  d2_2 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_2<span class="o">)</span>
  d2_2 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters<span class="k">*</span>4, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_2<span class="o">)</span>

  d2_2 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2_2<span class="o">)</span>
  d2_2 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_2<span class="o">)</span>
  d2_2 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters, <span class="o">(</span>5, 5<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_2<span class="o">)</span>

  d2_2 <span class="o">=</span> concatenate<span class="o">([</span>input, d2_1, d2_2]<span class="o">)</span>

  <span class="c"># - L3</span>
  d2_3 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2_2<span class="o">)</span>
  d2_3 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_3<span class="o">)</span>
  d2_3 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters<span class="k">*</span>4, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_3<span class="o">)</span>

  d2_3 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2_3<span class="o">)</span>
  d2_3 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_3<span class="o">)</span>
  d2_3 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters, <span class="o">(</span>5, 5<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_3<span class="o">)</span>

  d2_3 <span class="o">=</span> concatenate<span class="o">([</span>input, d2_1, d2_2, d2_3]<span class="o">)</span>

  <span class="c"># - L4</span>
  d2_4 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2_3<span class="o">)</span>
  d2_4 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_4<span class="o">)</span>
  d2_4 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters<span class="k">*</span>4, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_4<span class="o">)</span>

  d2_4 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2_4<span class="o">)</span>
  d2_4 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>d2_4<span class="o">)</span>
  d2_4 <span class="o">=</span> Conv2D<span class="o">(</span>num_filters, <span class="o">(</span>5, 5<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>d2_4<span class="o">)</span>

  d2_4 <span class="o">=</span> concatenate<span class="o">([</span>input, d2_1, d2_2, d2_3, d2_4]<span class="o">)</span>
  <span class="k">return </span>d2_4

def dd_net<span class="o">(</span>ldct_img, <span class="nv">is_training</span><span class="o">=</span> True<span class="o">)</span>:
    net <span class="o">=</span> ldct_img
    num_filter <span class="o">=</span> 16
    <span class="c"># ---A1 Layer-----------------------</span>
    h_conv1 <span class="o">=</span> Conv2D<span class="o">(</span>16, <span class="o">(</span>7, 7<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">use_bias</span><span class="o">=</span>True, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))(</span>net<span class="o">)</span>
    a1 <span class="o">=</span> MaxPooling2D<span class="o">((</span>3, 3<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>2, 2<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="o">)</span> <span class="o">(</span>h_conv1<span class="o">)</span>
    <span class="c"># images 256 X 256</span>
    d1 <span class="o">=</span> denseblock<span class="o">(</span>a1<span class="o">)</span>

    a1 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d1<span class="o">)</span>
    a1 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>a1<span class="o">)</span>
    h_conv1_T <span class="o">=</span> Conv2D<span class="o">(</span>16, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">use_bias</span><span class="o">=</span>True<span class="o">)</span> <span class="o">(</span>a1<span class="o">)</span>

    <span class="c"># ----A2 Layer---------------------</span>
    a2 <span class="o">=</span> MaxPooling2D<span class="o">((</span>2, 2<span class="o">)</span>,strides<span class="o">=(</span>2, 2<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="o">)</span> <span class="o">(</span>h_conv1_T<span class="o">)</span>
    <span class="c"># images 128 X 128 d</span>
    d2 <span class="o">=</span> denseblock<span class="o">(</span>a2<span class="o">)</span>

    a2 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d2<span class="o">)</span>
    a2 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>a2<span class="o">)</span>
    h_conv2_T <span class="o">=</span> Conv2D<span class="o">(</span>16, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">use_bias</span><span class="o">=</span>True<span class="o">)</span> <span class="o">(</span>a2<span class="o">)</span>
    <span class="c"># images 128 X 128</span>

    <span class="c"># # ----A3 Layer----------------------</span>
    a3 <span class="o">=</span> MaxPooling2D<span class="o">((</span>2, 2<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>2, 2<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="o">)</span> <span class="o">(</span>h_conv2_T<span class="o">)</span>
    <span class="c"># images 64 X 64</span>
    d3 <span class="o">=</span> denseblock<span class="o">(</span>a3<span class="o">)</span>

    a3 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d3<span class="o">)</span>
    a3 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>a3<span class="o">)</span>
    h_conv3_T <span class="o">=</span> Conv2D<span class="o">(</span>16, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">use_bias</span><span class="o">=</span>True<span class="o">)</span> <span class="o">(</span>a3<span class="o">)</span>

    <span class="c"># ----A4 Layer----------------------</span>
    a4 <span class="o">=</span> MaxPooling2D<span class="o">((</span>2, 2<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>2, 2<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="o">)</span> <span class="o">(</span>h_conv3_T<span class="o">)</span>
    <span class="c"># images 32 X 3</span>
    d4 <span class="o">=</span> denseblock<span class="o">(</span>a4<span class="o">)</span>

    a4 <span class="o">=</span> BatchNormalization<span class="o">()(</span>d4<span class="o">)</span>
    a4 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>a4<span class="o">)</span>
    h_conv4_T <span class="o">=</span> Conv2D<span class="o">(</span>16, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">)</span>, <span class="nv">use_bias</span><span class="o">=</span>True<span class="o">)</span> <span class="o">(</span>a4<span class="o">)</span>

    <span class="c"># #----B1 Layer-----------------------</span>
    b1 <span class="o">=</span> UpSampling2D<span class="o">((</span>2, 2<span class="o">)</span>, <span class="nv">interpolation</span><span class="o">=</span><span class="s2">"nearest"</span><span class="o">)</span> <span class="o">(</span>h_conv4_T<span class="o">)</span>
    <span class="c"># images 64 X 64</span>
    b1 <span class="o">=</span> concatenate<span class="o">([</span>b1, h_conv3_T]<span class="o">)</span>

    b1 <span class="o">=</span> Conv2DTranspose<span class="o">(</span>num_filter<span class="k">*</span>2, <span class="o">(</span>5, 5<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b1<span class="o">)</span>
    b1 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>b1<span class="o">)</span>
    b1 <span class="o">=</span> BatchNormalization<span class="o">()(</span>b1<span class="o">)</span>

    b1 <span class="o">=</span> Conv2DTranspose<span class="o">(</span>16, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b1<span class="o">)</span>
    b1 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>b1<span class="o">)</span>
    b1 <span class="o">=</span> BatchNormalization<span class="o">()(</span>b1<span class="o">)</span>

    <span class="c"># #----B2 Layer-----------------------</span>
    b2 <span class="o">=</span> UpSampling2D<span class="o">((</span>2, 2<span class="o">)</span>, <span class="nv">interpolation</span><span class="o">=</span><span class="s2">"nearest"</span><span class="o">)</span> <span class="o">(</span>b1<span class="o">)</span>
    <span class="c"># images 128 X 128</span>
    b2 <span class="o">=</span> concatenate<span class="o">([</span>b2, h_conv2_T]<span class="o">)</span>

    b2 <span class="o">=</span> Conv2DTranspose<span class="o">(</span>num_filter<span class="k">*</span>2, <span class="o">(</span>5, 5<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b2<span class="o">)</span>
    b2 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>b2<span class="o">)</span>
    b2 <span class="o">=</span> BatchNormalization<span class="o">()(</span>b2<span class="o">)</span>

    b2 <span class="o">=</span> Conv2DTranspose<span class="o">(</span>16, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b2<span class="o">)</span>
    b2 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>b2<span class="o">)</span>
    b2 <span class="o">=</span> BatchNormalization<span class="o">()(</span>b2<span class="o">)</span>

    <span class="c">#----B3 Layer------------------------conv6</span>
    b3 <span class="o">=</span> UpSampling2D<span class="o">((</span>2, 2<span class="o">)</span>,interpolation<span class="o">=</span><span class="s2">"nearest"</span><span class="o">)</span> <span class="o">(</span>b2<span class="o">)</span>
    <span class="c"># images 256 X 256</span>
    b3 <span class="o">=</span> concatenate<span class="o">([</span>b3, h_conv1_T]<span class="o">)</span>

    b3 <span class="o">=</span> Conv2DTranspose<span class="o">(</span>num_filter<span class="k">*</span>2, <span class="o">(</span>5, 5<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b3<span class="o">)</span>
    b3 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>b3<span class="o">)</span>
    b3 <span class="o">=</span> BatchNormalization<span class="o">()(</span>b3<span class="o">)</span>

    b3 <span class="o">=</span> Conv2DTranspose<span class="o">(</span>16, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">padding</span><span class="o">=</span><span class="s1">'same'</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b3<span class="o">)</span>
    b3 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>b3<span class="o">)</span>
    b3 <span class="o">=</span> BatchNormalization<span class="o">()(</span>b3<span class="o">)</span>

    <span class="c">#----B4 Layer-------------------------</span>
    b4 <span class="o">=</span> UpSampling2D<span class="o">((</span>2, 2<span class="o">)</span>,interpolation<span class="o">=</span><span class="s2">"nearest"</span><span class="o">)</span> <span class="o">(</span>b3<span class="o">)</span>
    <span class="c"># images 512 X 512</span>
    b4 <span class="o">=</span> concatenate<span class="o">([</span>b4, h_conv1]<span class="o">)</span>
    b4 <span class="o">=</span> Conv2DTranspose<span class="o">(</span>num_filter<span class="k">*</span>2, <span class="o">(</span>5, 5<span class="o">)</span>,padding<span class="o">=</span><span class="s1">'same'</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b4<span class="o">)</span>
    b4 <span class="o">=</span> Activation<span class="o">(</span><span class="s1">'relu'</span><span class="o">)(</span>b4<span class="o">)</span>
    <span class="c"># b4 = BatchNormalization()(b4)</span>

    output_img <span class="o">=</span> Conv2DTranspose<span class="o">(</span>1, <span class="o">(</span>1, 1<span class="o">)</span>, <span class="nv">strides</span><span class="o">=(</span>1, 1<span class="o">))</span> <span class="o">(</span>b4<span class="o">)</span>
    <span class="c"># output_img = Activation('relu')(output_img) # in paper but DIDN'T CONVERGE</span>
    <span class="c"># ------ end B4 layer</span>

    denoised_image <span class="o">=</span> Subtract<span class="o">()([</span>net, output_img]<span class="o">)</span>
    <span class="k">return </span>denoised_image


</code></pre></div></div>

<p>Each training process took approximately 24 hours.</p>

<h4 id="how-to-create-a-python-environment-and-train">How to create a python environment and train</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) [npovey@ka ~]$ conda create -n keras-gpu python=3.6 numpy scipy keras-gpu
(base) [npovey@ka unet4]$ conda activate keras-gpu
(keras-gpu) [npovey@ka unet4]$ pip install pandas
(keras-gpu) [npovey@ka unet4]$ pip install Pillow
(keras-gpu) [npovey@ka unet4]$ pip install matplotlib
(keras-gpu) [npovey@ka unet4]$ python main.py
</code></pre></div></div>

<h4 id="how-to-train">How to train</h4>

<p>In main.py  (line 77)  use train.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#parser.add_argument('--phase', dest='phase', default='test', help='test')
</span><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--phase'</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s">'phase'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">help</span> <span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="how-to-test">How to test</h4>

<p>Change from train to test in main.py  line 77</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#parser.add_argument('--phase', dest='phase', default='test', help='test')
</span><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--phase'</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s">'phase'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">help</span> <span class="o">=</span><span class="s">'train'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="other-useful-info">Other useful info</h4>

<p>Sign in into remote linux machines</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nps-MacBook-Air-2:Desktop np<span class="nv">$ </span>ssh npovey@ka...
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">ls
</span>main.py  model.py  model.py~  utils.py
</code></pre></div></div>

<p>Got  core dumped problem as all GPUs were taken</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Aborted <span class="o">(</span>core dumped<span class="o">)</span>
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="err">$</span>
</code></pre></div></div>

<p>Check available GPUs</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>nvidia-smi <span class="nt">-L</span>
GPU 0: Quadro RTX 5000 <span class="o">(</span>UUID: GPU-1f923d52-ea64-f463-96a4-3bece2719a8b<span class="o">)</span>
GPU 1: Quadro RTX 5000 <span class="o">(</span>UUID: GPU-20947179-1907-5468-1325-a3fc16f5a54e<span class="o">)</span>
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>nvidia-smi
Fri Mar  6 14:25:38 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  Quadro RTX 5000     Off  | 00000000:67:00.0 Off |                  Off |
| 43%   68C    P2   212W / 230W |  15871MiB / 16095MiB |     94%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Quadro RTX 5000     Off  | 00000000:68:00.0 Off |                  Off |
| 55%   78C    P2   221W / 230W |  15869MiB / 16092MiB |     96%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|<span class="o">=============================================================================</span>|
|    0     78799      C   python                                     15861MiB |
|    1     26617      C   python                                     15859MiB |
+-----------------------------------------------------------------------------+
WARNING: infoROM is corrupted at gpu 0000:67:00.0
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="err">$</span>

</code></pre></div></div>

<p>Looks like both GPUs are taken</p>

<p>Trying a little bit later</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">(</span>base<span class="o">)</span> <span class="o">[</span>npovey@ka ~]<span class="nv">$ </span>nvidia-smi
Fri Mar  6 20:23:45 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.87.00    Driver Version: 418.87.00    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  Quadro RTX 5000     Off  | 00000000:67:00.0 Off |                  Off |
| 43%   65C    P2    74W / 230W |  15871MiB / 16095MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Quadro RTX 5000     Off  | 00000000:68:00.0 Off |                  Off |
| 35%   35C    P0    N/A /  N/A |      0MiB / 16092MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|<span class="o">=============================================================================</span>|
|    0     78799      C   python                                     15861MiB |
+-----------------------------------------------------------------------------+
WARNING: infoROM is corrupted at gpu 0000:67:00.0
<span class="o">(</span>base<span class="o">)</span> <span class="o">[</span>npovey@ka ~]<span class="err">$</span>
</code></pre></div></div>

<p>We can observe that GPU1 is free to run our code.</p>

<p>Run the code on the remote linux machine</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka data]<span class="nv">$ </span><span class="nb">cd </span>dd_net/
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">source </span>activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="err">$</span>
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>python main.py
</code></pre></div></div>

<p>As the code takes long time to run I recommend running it using screen</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">source </span>activate keras-gpu
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>python main.py
<span class="o">(</span>press ctlr+A, D to detach from screen<span class="o">)</span>
<span class="o">[</span>detached from 6921.dd_net1]

</code></pre></div></div>

<p>To copy result to a local machine and view them</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nps-MacBook-Air-2:Desktop np<span class="nv">$ </span>scp <span class="nt">-r</span> npovey@ka:/home/npovey/data/dd_net/output_dd_net_60.txt DD_Net/
npovey@ka<span class="s1">'s password:
output_dd_net_60.txt                          100%   32KB 321.5KB/s   00:00    
nps-MacBook-Air-2:Desktop np$


</span></code></pre></div></div>

<h5 id="run-sparseview_60">run sparseview_60</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">source </span>activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dncnn1]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_60.txt
</code></pre></div></div>

<h5 id="run-sparseview_90">run sparseview_90</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">source </span>activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_90.txt

</code></pre></div></div>

<p>Got good results:</p>

<h5 id="run-sparseview_180">run sparseview_180</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">source </span>activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_180.txt
</code></pre></div></div>

<h5 id="run-ldcd_7e4">run ldcd_7e4</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">source </span>activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_ldct_7e4.txt
</code></pre></div></div>

<p>Epoch 1/50 Avg PSNR: 40.91373649562122</p>

<p>Epoch 2/50 Avg PSNR: 41.007181141963734</p>

<p>Epoch 3/50 Avg PSNR: 32.428249836375585</p>

<p>Epoch 4/50 Avg PSNR: 32.42561434856395</p>

<p>……</p>

<p>Epoch 50/50 Avg PSNR: 32.427569692000205</p>

<p>#####run ldcd_2e5</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">source </span>activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_ldct_2e5.txt
</code></pre></div></div>

<p>Epoch 0: Avg PSNR: 41.967376293118136</p>

<p>Epoch 1: Avg PSNR: 37.859690812973035</p>

<p>Epoch 2: Avg PSNR: 39.812348874868206</p>

<p>Epoch 9: Avg PSNR: 41.398334420237376</p>

<h5 id="delete-old-data-before-training-on-a-new-dataset">Delete old data before training on a new dataset</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ps aux <span class="o">&gt;</span>text.txt
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">kill</span> <span class="nt">-KILL</span> 10371
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> logs/
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> checkpoints
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> ndct_train.tfrecord
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> ldct_train.tfrecord
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> ndct_test.tfrecord
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> ldct_test.tfrecord
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> __pycache__/
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> output_samples/
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span><span class="nb">rm</span> <span class="nt">-r</span> <span class="nb">test</span>/

<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_60_2.txt

</code></pre></div></div>

<h5 id="train">Train</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka dd_net]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka dncnn1]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_60.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_ldct_7e4.txt
</code></pre></div></div>

<p>copy to local desktop</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nps-MacBook-Air-2:Desktop np<span class="nv">$ </span>scp <span class="nt">-r</span> npovey@ka:/home/npovey/data/ddnet2/main.py <span class="nb">.</span>
npovey@ka<span class="s1">'s password:
main.py                                       100% 7690   305.0KB/s   00:00    
nps-MacBook-Air-2:Desktop np$ scp -r npovey@ka:/home/npovey/data/ddnet2/model.py .
npovey@ka'</span>s password:
model.py                                                                                                               100%   33KB 562.2KB/s   00:00    
<span class="o">(</span>base<span class="o">)</span> nps-MacBook-Air-2:Desktop np<span class="err">$</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_ldct_2e5.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_ldct_1e5.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_ldct_2e5.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_sparseview_60.txt
CTRL+A D <span class="nb">exit </span>screens mode
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_sparseview_90.txt
CTRL+A D <span class="nb">exit </span>screens mode
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>screen <span class="nt">-S</span> dd_net1
<span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> output_ddnet_sparseview_180.txt
CTRL+A D <span class="nb">exit </span>screens mode
</code></pre></div></div>

<h5 id="to-test">To test</h5>

<p>Change from train to test in main.py  line 77</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#parser.add_argument('--phase', dest='phase', default='test', help='test')
</span><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--phase'</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s">'phase'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s">'train'</span><span class="p">,</span> <span class="n">help</span> <span class="o">=</span><span class="s">'train'</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> test_180.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> test_90.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> test_7e4.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> test_1e5.txt
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>conda activate keras-gpu
<span class="o">(</span>keras-gpu<span class="o">)</span> <span class="o">[</span>npovey@ka ddnet2]<span class="nv">$ </span>python main.py <span class="o">&gt;</span> test_2e5.txt
</code></pre></div></div>

  </div><a class="u-url" href="/update/2020/04/01/DD_Net-linux.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">can code</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">can code</li><li><a class="u-email" href="mailto:npovey2atgmail">npovey2atgmail</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/jekyll"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jekyll</span></a></li><li><a href="https://www.twitter.com/jekyllrb"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">jekyllrb</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
